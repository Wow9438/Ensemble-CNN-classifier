{"cells":[{"cell_type":"code","execution_count":27,"metadata":{"execution":{"iopub.execute_input":"2024-04-28T18:18:43.088348Z","iopub.status.busy":"2024-04-28T18:18:43.087262Z","iopub.status.idle":"2024-04-28T18:18:43.093843Z","shell.execute_reply":"2024-04-28T18:18:43.092860Z","shell.execute_reply.started":"2024-04-28T18:18:43.088308Z"},"trusted":true},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","import torchvision\n","from torchvision import datasets, transforms, models\n","# import torchvision.models as models\n","import torch.nn.functional as F\n","import torch.optim as optim\n","from tqdm import tqdm\n","import numpy as np\n","import csv"]},{"cell_type":"code","execution_count":28,"metadata":{"execution":{"iopub.execute_input":"2024-04-28T18:18:43.096177Z","iopub.status.busy":"2024-04-28T18:18:43.095710Z","iopub.status.idle":"2024-04-28T18:18:43.104106Z","shell.execute_reply":"2024-04-28T18:18:43.103207Z","shell.execute_reply.started":"2024-04-28T18:18:43.096141Z"},"trusted":true},"outputs":[],"source":["device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"]},{"cell_type":"code","execution_count":29,"metadata":{"execution":{"iopub.execute_input":"2024-04-28T18:18:43.105637Z","iopub.status.busy":"2024-04-28T18:18:43.105299Z","iopub.status.idle":"2024-04-28T18:18:43.112232Z","shell.execute_reply":"2024-04-28T18:18:43.111323Z","shell.execute_reply.started":"2024-04-28T18:18:43.105604Z"},"trusted":true},"outputs":[],"source":["transform = transforms.Compose([\n","    transforms.Resize((224, 224)),  \n","    transforms.ToTensor(),  \n","    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])  \n","])"]},{"cell_type":"code","execution_count":30,"metadata":{"execution":{"iopub.execute_input":"2024-04-28T18:18:43.113743Z","iopub.status.busy":"2024-04-28T18:18:43.113382Z","iopub.status.idle":"2024-04-28T18:18:58.565128Z","shell.execute_reply":"2024-04-28T18:18:58.564296Z","shell.execute_reply.started":"2024-04-28T18:18:43.113719Z"},"trusted":true},"outputs":[],"source":["train_dir = '/kaggle/input/iith-dl-contest-2024/train/train'\n","train_data  = datasets.ImageFolder(train_dir, transform = transform)\n","train_loader = torch.utils.data.DataLoader(train_data, batch_size=32, shuffle=True)"]},{"cell_type":"code","execution_count":31,"metadata":{"execution":{"iopub.execute_input":"2024-04-28T18:18:58.567699Z","iopub.status.busy":"2024-04-28T18:18:58.567413Z","iopub.status.idle":"2024-04-28T18:18:59.543190Z","shell.execute_reply":"2024-04-28T18:18:59.542201Z","shell.execute_reply.started":"2024-04-28T18:18:58.567674Z"},"trusted":true},"outputs":[{"data":{"text/plain":["ResNet(\n","  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n","  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","  (relu): ReLU(inplace=True)\n","  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n","  (layer1): Sequential(\n","    (0): BasicBlock(\n","      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (1): BasicBlock(\n","      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","  )\n","  (layer2): Sequential(\n","    (0): BasicBlock(\n","      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (downsample): Sequential(\n","        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (1): BasicBlock(\n","      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","  )\n","  (layer3): Sequential(\n","    (0): BasicBlock(\n","      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (downsample): Sequential(\n","        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (1): BasicBlock(\n","      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","  )\n","  (layer4): Sequential(\n","    (0): BasicBlock(\n","      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (downsample): Sequential(\n","        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (1): BasicBlock(\n","      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","  )\n","  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n","  (fc): Linear(in_features=512, out_features=50, bias=True)\n",")"]},"execution_count":31,"metadata":{},"output_type":"execute_result"}],"source":["# Load pretrained Convnext_tiny\n","convnext_model = models.convnext_tiny(weights= None).to(device)\n","convnext_model.classifier[2] = nn.Linear(768,50)\n","convnext_model.load_state_dict(torch.load('Convnext_tiny_model_weights17.pth', map_location=torch.device('cpu')))\n","#change number here to use weights from a different epoch.\n","convnext_model.to(device)\n","convnext_model.eval()  # Set to evaluation mode\n","\n","# Load pretrained Resnet\n","resnet_model = models.resnet18(weights= None).to(device)\n","resnet_model.fc = nn.Linear(512,50)\n","resnet_model.load_state_dict(torch.load('resnetmodelweights18.pth', map_location=torch.device('cpu')))\n","#change number here to use weights from a different epoch.\n","resnet_model.to(device)\n","resnet_model.eval()  # Set to evaluation mode\n"]},{"cell_type":"code","execution_count":32,"metadata":{"execution":{"iopub.execute_input":"2024-04-28T18:18:59.544734Z","iopub.status.busy":"2024-04-28T18:18:59.544400Z","iopub.status.idle":"2024-04-28T18:18:59.559205Z","shell.execute_reply":"2024-04-28T18:18:59.558263Z","shell.execute_reply.started":"2024-04-28T18:18:59.544708Z"},"trusted":true},"outputs":[],"source":["class Ensemble(nn.Module):\n","    def __init__(self, models):\n","        super(Ensemble, self).__init__()\n","        self.models = nn.ModuleList(models)  # Convert list of models to ModuleList\n","\n","    def forward(self, x):\n","        outputs = [model(x) for model in self.models]\n","        return torch.stack(outputs).mean(0)\n","\n","# Define the ensemble model\n","ensemble_model = Ensemble([resnet_model, convnext_model]).to(device)\n","\n","# Now ensemble_model.parameters() should contain the parameters of the models in the ensemble\n","\n","# Define loss criterion and optimizer for ensemble model\n","loss_func = nn.CrossEntropyLoss()\n","optimizer = optim.Adam(ensemble_model.parameters(), lr=0.001)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":[]},{"cell_type":"code","execution_count":33,"metadata":{"execution":{"iopub.execute_input":"2024-04-28T18:18:59.560653Z","iopub.status.busy":"2024-04-28T18:18:59.560340Z","iopub.status.idle":"2024-04-28T18:19:12.072992Z","shell.execute_reply":"2024-04-28T18:19:12.072169Z","shell.execute_reply.started":"2024-04-28T18:18:59.560623Z"},"trusted":true},"outputs":[],"source":["test_dir = '/kaggle/input/iith-dl-contest-2024/test'\n","test_data  = datasets.ImageFolder(test_dir, transform = transform)\n","test_loader = torch.utils.data.DataLoader(test_data, batch_size=32, shuffle=False)"]},{"cell_type":"code","execution_count":34,"metadata":{"execution":{"iopub.execute_input":"2024-04-28T18:19:12.074513Z","iopub.status.busy":"2024-04-28T18:19:12.074212Z","iopub.status.idle":"2024-04-28T18:19:12.078649Z","shell.execute_reply":"2024-04-28T18:19:12.077736Z","shell.execute_reply.started":"2024-04-28T18:19:12.074488Z"},"trusted":true},"outputs":[],"source":["import numpy as np\n","import csv"]},{"cell_type":"code","execution_count":35,"metadata":{"execution":{"iopub.execute_input":"2024-04-28T18:19:12.080425Z","iopub.status.busy":"2024-04-28T18:19:12.080054Z","iopub.status.idle":"2024-04-28T18:19:12.087613Z","shell.execute_reply":"2024-04-28T18:19:12.086771Z","shell.execute_reply.started":"2024-04-28T18:19:12.080379Z"},"trusted":true},"outputs":[],"source":["# Reverse the class to index mapping to index to class for prediction interpretation\n","classes = train_data.class_to_idx\n","idx_to_class = {idx: class_name for class_name, idx in classes.items()}"]},{"cell_type":"code","execution_count":36,"metadata":{"execution":{"iopub.execute_input":"2024-04-28T18:19:12.089148Z","iopub.status.busy":"2024-04-28T18:19:12.088797Z","iopub.status.idle":"2024-04-28T18:22:31.277405Z","shell.execute_reply":"2024-04-28T18:22:31.276678Z","shell.execute_reply.started":"2024-04-28T18:19:12.089116Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["100%|██████████| 1199/1199 [03:19<00:00,  6.02it/s]\n"]}],"source":["# List to store outputs\n","outputs_list = []\n","\n","# Process images and gather predictions\n","for images, _ in tqdm(test_loader):\n","    images = images.to(device)\n","    outputs = ensemble_model(images)\n","    _, predicted = torch.max(outputs, dim=1)\n","    outputs_list.append(predicted)\n","\n","# Concatenate all predictions into a single tensor\n","outputs = torch.cat(outputs_list).cpu().numpy()"]},{"cell_type":"code","execution_count":37,"metadata":{"execution":{"iopub.execute_input":"2024-04-28T18:22:31.279064Z","iopub.status.busy":"2024-04-28T18:22:31.278728Z","iopub.status.idle":"2024-04-28T18:22:31.325183Z","shell.execute_reply":"2024-04-28T18:22:31.324319Z","shell.execute_reply.started":"2024-04-28T18:22:31.279038Z"},"trusted":true},"outputs":[],"source":["import numpy as np\n","\n","# Convert class indices to class names\n","predicted_classes = np.array([idx_to_class[idx] for idx in outputs], dtype=object)\n","\n","# Generate image file names\n","file_names = [f\"{i}.JPEG\" for i in range(len(predicted_classes))]\n","\n","file_names = np.sort(file_names)"]},{"cell_type":"code","execution_count":38,"metadata":{"execution":{"iopub.execute_input":"2024-04-28T18:22:31.326618Z","iopub.status.busy":"2024-04-28T18:22:31.326336Z","iopub.status.idle":"2024-04-28T18:22:31.336034Z","shell.execute_reply":"2024-04-28T18:22:31.334973Z","shell.execute_reply.started":"2024-04-28T18:22:31.326594Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["[['0.JPEG' 'n02808440']\n"," ['1.JPEG' 'n02480495']\n"," ['10.JPEG' 'n02226429']\n"," ...\n"," ['9997.JPEG' 'n02480495']\n"," ['9998.JPEG' 'n02395406']\n"," ['9999.JPEG' 'n01774750']]\n"]}],"source":["# Combine file names and predicted classes\n","table = np.column_stack((file_names, predicted_classes))\n","\n","# Print table (optional, can be commented out in production)\n","print(table)"]},{"cell_type":"code","execution_count":39,"metadata":{"execution":{"iopub.execute_input":"2024-04-28T18:22:31.337668Z","iopub.status.busy":"2024-04-28T18:22:31.337279Z","iopub.status.idle":"2024-04-28T18:22:31.433972Z","shell.execute_reply":"2024-04-28T18:22:31.433178Z","shell.execute_reply.started":"2024-04-28T18:22:31.337636Z"},"trusted":true},"outputs":[],"source":["# Write results to CSV file\n","with open('ensemble_submission', 'w', newline='') as file:\n","    wr = csv.writer(file)\n","    wr.writerow(['ID', 'Category'])\n","    wr.writerows(table)"]}],"metadata":{"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"databundleVersionId":8040143,"sourceId":73111,"sourceType":"competition"},{"sourceId":174247101,"sourceType":"kernelVersion"},{"sourceId":174338959,"sourceType":"kernelVersion"}],"dockerImageVersionId":30698,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"}},"nbformat":4,"nbformat_minor":4}
